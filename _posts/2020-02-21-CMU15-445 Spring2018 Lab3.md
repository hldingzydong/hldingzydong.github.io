---
layout: post
title:  CMU15-445 Spring2018 Lab3
date:   2020-02-21
author: hding
catalog: true
tags:
   - database
---
# [Lab3](https://15445.courses.cs.cmu.edu/fall2018/project3/)

## Overview 
实现Two-Phase Locking(2PL)和Strict Two-Phase Locking(S2PL),对deadlock的预防policy是“wait-die”:  
> Wait-Die ("Old Waits for Young")  
> If requesting txn has higher priority than holding txn, then requesting txn waits for holding txn.  
> Otherwise requesting txn aborts.

由两张图介绍2PL与S2PL:
![2PL](/img/DataBase/2PL.jpeg)
![S2PL](/img/DataBase/S2PL.jpeg)


## Task #1 - LockManager
就像实现一个Buffer Pool Manager一样,这次需要实现一个Lock Manager,也是为整个DBMS服务,它管理着txn对锁的获取,升级和释放.

#### std::condition_variable
在2PL中,当某个锁被释放时,我们需要通过某种方法通知waiting该锁的txn,现在可以去尝试获得锁了.在这里我们使用std::condition_variable.  
以下是对[std::condition_variable](https://en.cppreference.com/w/cpp/thread/condition_variable)的介绍,摘自cppreference:  
> The condition_variable class is a synchronization primitive that can be used to block a thread, or multiple threads at the same time, until another thread both modifies a shared variable (the condition), and notifies the condition_variable.  
> The thread that intends to modify the variable has to:
> 1. acquire a std::mutex (typically via std::lock_guard)
> 2. perform the modification while the lock is held
> 3. execute notify_one or notify_all on the std::condition_variable (the lock does not need to be held for notification)  

> Even if the shared variable is atomic, it must be modified under the mutex in order to correctly publish the modification to the waiting thread.  
> Any thread that intends to wait on std::condition_variable has to: 
> 1. acquire a std::unique_lock<std::mutex>, on the same mutex as used to protect the shared variable
> 2. execute wait, wait_for, or wait_until. The wait operations atomically release the mutex and suspend the execution of the thread.
> 3. When the condition variable is notified, a timeout expires, or a spurious wakeup occurs, the thread is awakened, and the mutex is atomically reacquired. The thread should then check the condition and resume waiting if the wake up was spurious.

在此次lab中,主要使用std::condition_variable的两个function:  
1. [wait()](https://en.cppreference.com/w/cpp/thread/condition_variable/wait)
```c++
template< class Predicate >
void wait(std::unique_lock<std::mutex>& lock, Predicate pred );
```
2. [notify_all()](https://en.cppreference.com/w/cpp/thread/condition_variable/notify_all)
```c++
void notify_all() noexcept;
```


#### 数据成员
首先是对Lock Manager的定义:
```c++
bool strict_2PL_;   // 作为构造参数传入,true表示使用S2PL
std::mutex mutex_;  // 对std::condition_variable的使用需要用到
std::condition_variable cond; // std::condition_variable
std::unordered_map<RID, Waiting> lock_table_; // 根据RID找到等待获取该tuple上的锁的txn
```
对Waiting的定义,其中包含metadata:
```c++
struct Waiting {
    size_t exclusive_cnt = 0;  // how many exclusive requests
    txn_id_t oldest = -1;      // wait-die: txn older than `oldest`(<) can wait or die
    std::list<Request> list;   // 对该tuple的一系列请求
  };
```
对于Request的定义:
```c++
struct Request {
    explicit Request(txn_id_t id, LockMode m, bool g) :
        txn_id(id), mode(m), granted(g) {}
    txn_id_t txn_id;          // 标示此次对该tuple的请求是由哪个txn发起,并用作deadlock预防
    LockMode mode = LockMode::SHARED; 
    bool granted = false;     // 标示对于该请求是否给予锁
  };
```

除此之外,还需要了解到txn的各种状态:
```
Transaction states:
    _________________________
    |                         v
 GROWING -> SHRINKING -> COMMITTED   ABORTED
    |__________|________________________^

```
```c++
enum class TransactionState { GROWING, SHRINKING, COMMITTED, ABORTED };
```


#### API 
现在我们可以实现Lock Manager的API:
1. LockShared(Transaction, RID): 获取RID的读锁
2. LockExclusive(Transaction, RID): 获取RID的写锁
3. LockUpgrade(Transaction, RID): 将对RID的读锁upgrade为写锁
4. Unlock(Transaction, RID)

###### LockShared
首先构建Request,然后根据deadlock的预防policy来决定是否abort该txn.接下来使用std::condition_variable来跑Predicate.该Predicate判断此时是否能获取读锁,若不能则阻塞,直到被其他线程唤醒.
当被唤醒并且此时可以获取读锁时,则更新状态,同时唤醒所有的因为该condition_variable阻塞的线程.

注意,condition_variable.wait()里的Predicate,当返回false时阻塞,只有被notify后才会再次执行一遍。当返回true时则可以继续向下执行,否则一直阻塞.
```c++
bool LockManager::LockShared(Transaction *txn, const RID &rid)
{
  std::unique_lock<std::mutex> latch(mutex_);
  if (txn->GetState() == TransactionState::ABORTED)
  {
    return false;
  }

  assert(txn->GetState() == TransactionState::GROWING);

  Request req{txn->GetTransactionId(), LockMode::SHARED, false};
  if (lock_table_.count(rid) == 0)  // 此次Request是对该tuple的第一次request
  {
    lock_table_[rid].exclusive_cnt = 0;
    lock_table_[rid].oldest = txn->GetTransactionId();
    lock_table_[rid].list.push_back(req);
  }
  else
  {
    if (lock_table_[rid].exclusive_cnt != 0 &&
        txn->GetTransactionId() > lock_table_[rid].oldest)
    {
      // deadlock预防
      txn->SetState(TransactionState::ABORTED);
      return false;
    }
    if (lock_table_[rid].oldest > txn->GetTransactionId())
    {
      lock_table_[rid].oldest = txn->GetTransactionId();
    }
    lock_table_[rid].list.push_back(req);
  }

  // 等待条件变量,判断是否可以获取读锁
  Request *cur = nullptr;
  cond.wait(latch, [&]() -> bool {
    bool all_shared = true, all_granted = true;
    for (auto &r : lock_table_[rid].list)
    {
      if (r.txn_id != txn->GetTransactionId())
      {
        if (r.mode != LockMode::SHARED || !r.granted)
        {
          return false;
        }
      }
      else
      {
        cur = &r;
        return all_shared && all_granted;
      }
    }
    return false;
  });

  assert(cur != nullptr && cur->txn_id == txn->GetTransactionId());
  // 更新状态
  cur->granted = true;
  txn->GetSharedLockSet()->insert(rid);

  cond.notify_all();
  return true;
}
```

###### LockExclusive
和获取读锁的过程相似,区别在于当获取写锁时,需要更新lock_table_[rid].exclusive_cnt,还有判断是否此时可以获取写锁的Predicate。
```c++
bool LockManager::LockExclusive(Transaction *txn, const RID &rid)
{
  std::unique_lock<std::mutex> latch(mutex_);
  if (txn->GetState() == TransactionState::ABORTED)
  {
    return false;
  }

  assert(txn->GetState() == TransactionState::GROWING);

  Request req{txn->GetTransactionId(), LockMode::EXCLUSIVE, false};
  if (lock_table_.count(rid) == 0)
  {
    lock_table_[rid].oldest = txn->GetTransactionId();
    lock_table_[rid].list.push_back(req);
  }
  else
  {
    // 如果该请求事务不比等待链表中最老的还老，就die
    if (txn->GetTransactionId() > lock_table_[rid].oldest)
    {
      txn->SetState(TransactionState::ABORTED);
      return false;
    }

    // 否则就wait
    lock_table_[rid].oldest = txn->GetTransactionId();
    lock_table_[rid].list.push_back(req);
  }

  ++lock_table_[rid].exclusive_cnt;

  // 排它锁只有在等待队列中的第一个才能获得锁
  cond.wait(latch, [&]() -> bool {
    return lock_table_[rid].list.front().txn_id == txn->GetTransactionId();
  });

  assert(lock_table_[rid].list.front().txn_id == txn->GetTransactionId());

  lock_table_[rid].list.front().granted = true;
  txn->GetExclusiveLockSet()->insert(rid);
  return true;
}
```

###### Unlock
首先要根据strict_2PL_以及txn的状态来判断Unlock是否会让txn abort。  
然后遍历对该tuple的Request的list。当遍历到该txn对应的Request时,根据它是否是当前第一个Request以及它获得的是否是写锁,决定要不要唤醒所有阻塞的线程.在unlock后需要把该Request从tuple的list擦除掉。
```c++
bool LockManager::Unlock(Transaction *txn, const RID &rid)
{
  std::unique_lock<std::mutex> latch(mutex_);

  if (strict_2PL_)
  {
    if (txn->GetState() != TransactionState::COMMITTED &&
        txn->GetState() != TransactionState::ABORTED)
    {
      txn->SetState(TransactionState::ABORTED);
      return false;
    }
  }else
  {
    if (txn->GetState() == TransactionState::GROWING)
    {
      txn->SetState(TransactionState::SHRINKING);
    }
  }

  assert(lock_table_.count(rid));
  for (auto it = lock_table_[rid].list.begin();
       it != lock_table_[rid].list.end(); ++it)
  {
    if (it->txn_id == txn->GetTransactionId())
    {
      bool first = it == lock_table_[rid].list.begin();
      bool exclusive = it->mode == LockMode::EXCLUSIVE;

      if (exclusive)
      {
        --lock_table_[rid].exclusive_cnt;
      }
      lock_table_[rid].list.erase(it);

      if (first || exclusive)
      {
        cond.notify_all();
      }
      break;
    }
  }
  return true;
}
```

###### LockUpgrade
假设senario是:某个txn刚开始尝试获取读锁,但是后来它发现它还要写该tuple,但之前已经尝试获取读锁了,所以要对读锁升级.  
首先要找到当前txn在list<Request>的位置,标记为src;还要找到它要移动至的位置,即它的"读锁request"后面的第一个“写锁request”的前一个位置,将其标记为tgt.  
如果发现有其他的txn也在尝试upgrade他们的锁时,将当前txn abort.  
剩下的和获取写锁过程差不多.
```c++
bool LockManager::LockUpgrade(Transaction *txn, const RID &rid)
{
  std::unique_lock<std::mutex> latch(mutex_);
  if (txn->GetState() == TransactionState::ABORTED)
  {
    return false;
  }

  assert(txn->GetState() == TransactionState::GROWING);

  // 1. move cur request to the end of `shared` period
  // 2. change granted to false
  // 3. change lock mode to EXCLUSIVE
  auto src = lock_table_[rid].list.end(), tgt = src;
  
  for (auto it = lock_table_[rid].list.begin();
       it != lock_table_[rid].list.end(); ++it)
  {
    if (it->txn_id == txn->GetTransactionId())
    {
      src = it;
    }
    if (src != lock_table_[rid].list.end())
    {
      if (it->mode == LockMode::EXCLUSIVE)
      {
        tgt = it;
        break;
      }
    }
  }
  assert(src != lock_table_[rid].list.end());

  // deadlock 预防policy
  for (auto it = lock_table_[rid].list.begin(); it != tgt; ++it)
  {
    if (it->txn_id < src->txn_id)
    {
      return false;
    }
  }

  Request req = *src;
  req.granted = false;
  req.mode = LockMode::EXCLUSIVE;

  lock_table_[rid].list.insert(tgt, req);
  lock_table_[rid].list.erase(src);

  // 判断是否此时可以获取写锁
  cond.wait(latch, [&]() -> bool {
    return lock_table_[rid].list.front().txn_id == txn->GetTransactionId();
  });

  assert(lock_table_[rid].list.front().txn_id == txn->GetTransactionId() &&
         lock_table_[rid].list.front().mode == LockMode::EXCLUSIVE);

  lock_table_[rid].list.front().granted = true;

  txn->GetSharedLockSet()->erase(rid);
  txn->GetExclusiveLockSet()->insert(rid);
  return true;
}
```

> 由于Task2未能找到实现代码,故仅描述自己思路,并且用java实现思路(仅仅因为我有现成的java环境)

## Task #2 - DeadLock Detection 
构造wait-for图,监测是否存在cycle。基本思路是图的实现和DFS算法来找出cycle,图的实现采用数组+链表的结构。数组以txn_id作为idnex，存储该txn对应的链表。链表里存该txn在wait的其他txn_id。为了保证每次cycle会返回youngest的txn,需要保证链表的有序性。  

#### AP
1. AddEdge(txn_id_t t1, txn_id_t t2): 在图中增加一条从txn1到txn2的edge,若已存在则do nothing
2. RemoveEdge(txn_id_t t1, txn_id_t t2): 删除图中从txn1到txn2的edge,若不存在则do nothing
3. HasCycle(txn_id_t& txn_id): 判断图中是否有cycle,若没有则返回false;若有则将txn_id设置为youngest txn
4. GetEdgeList(): 拿到所有的edge

#### Code
Ps:未能想出来如何返回cycle中最youngest的txn_id.

Node的实现,就是数据结构中最常见的结点定义
```java
public class Node {
    int txn_id;
    Node next_node;

    Node(int txn_id) {
        this.txn_id = txn_id;
        next_node = null;
    }
}
```

DeadlockDetection类的实现:
```java
public class DeadlockDetection {
    // array
    private Node[] graph = new Node[100];

    void addEdge(int t1, int t2) {
        Node t1_head = graph[t1];
        Node t2_node = new Node(t2);

        if(t1_head == null) {
            graph[t1] = t2_node;
        }else if(t1_head.txn_id > t2) {
            t2_node.next_node = t1_head;
            graph[t1] = t2_node;
        }else{
            Node prev_node = t1_head;
            Node tmp_node = t1_head;
            while(tmp_node != null && tmp_node.txn_id < t2) {
                prev_node = tmp_node;
                tmp_node = tmp_node.next_node;
            }

            if(tmp_node == null) {
                prev_node.next_node = t2_node;
            }else if(tmp_node.txn_id > t2){
                t2_node.next_node = tmp_node;
                prev_node.next_node = t2_node;
            }
        }
    }

    void removeEdge(int t1, int t2) {
        Node t1_head = graph[t1];
        if(t1_head == null || t1_head.txn_id > t2) {
            return;
        }else if(t1_head.txn_id == t2){
            graph[t1] = null;
        }else {
            Node prev_node = t1_head;
            Node tmp_node = t1_head;
            while(tmp_node != null && tmp_node.txn_id < t2) {
                prev_node = tmp_node;
                tmp_node = tmp_node.next_node;
            }
            if(tmp_node != null && tmp_node.txn_id == t2) {
                prev_node.next_node = tmp_node.next_node;
            }
        }
    }

    // DFS
    // 无则返回-1,有则返回cycle中的一个txn_id
    int hasCycle() {
        for(int i = 0; i < graph.length; i++) {
            if(graph[i] != null) {
                Set<Integer> visited = new HashSet<Integer>();
                int tmp_res = hasCycleHelp(i, visited);
                if(tmp_res != -1) {
                    return tmp_res;
                }
            }
        }
        return -1;
    }

    private int hasCycleHelp(int index, Set<Integer> visited) {
        Node head = graph[index];

        if(head == null) {
            return -1;
        }else{
            Node tmp_node = head;
            while(tmp_node != null) {
                if(visited.contains(tmp_node.txn_id)) {
                    return tmp_node.txn_id;
                }else{
                    visited.add(tmp_node.txn_id);
                    int res = hasCycleHelp(tmp_node.txn_id, visited);
                    visited.remove(tmp_node.txn_id);
                    if(res == -1) {
                        tmp_node = tmp_node.next_node;
                    }else{
                        return res;
                    }
                }
            }
            return -1;
        }
    }

    List<Pair<Integer, Integer>> getEdgeList() {
        List<Pair<Integer, Integer>> edges = new ArrayList<Pair<Integer, Integer>>();
        for(int i = 0; i < graph.length; i++) {
            if(graph[i] != null) {
                Node tmp_node = graph[i];
                while(tmp_node != null) {
                    edges.add(new Pair<Integer, Integer>(i, tmp_node.txn_id));
                    tmp_node = tmp_node.next_node;
                }
            }
        }
        return edges;
    }

    public static void main(String[] args) {
        DeadlockDetection deadlockDetection = new DeadlockDetection();
        // test
        deadlockDetection.addEdge(0,2);
        deadlockDetection.addEdge(0,3);
        deadlockDetection.addEdge(1,3);
        deadlockDetection.addEdge(3,4);
        deadlockDetection.addEdge(4,1);

        System.out.println("hasCycle? " + deadlockDetection.hasCycle());
        System.out.println("edges number = " + deadlockDetection.getEdgeList().size());

        deadlockDetection.removeEdge(0,1);
        System.out.println("hasCycle? " + deadlockDetection.hasCycle());
        System.out.println("edges number = " + deadlockDetection.getEdgeList().size());

        deadlockDetection.removeEdge(3,4);
        System.out.println("hasCycle? " + deadlockDetection.hasCycle());
        System.out.println("edges number = " + deadlockDetection.getEdgeList().size());

        deadlockDetection.addEdge(2,4);
        deadlockDetection.addEdge(1,0);
        System.out.println("hasCycle? " + deadlockDetection.hasCycle());
        System.out.println("edges number = " + deadlockDetection.getEdgeList().size());
    }
}
```

程序的输出结果:
```
hasCycle? 3
edges number = 5
hasCycle? 3
edges number = 5
hasCycle? -1
edges number = 4
hasCycle? 2
edges number = 6
```


















