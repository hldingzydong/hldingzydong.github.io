---
layout: post
title:  CMU15-445 Spring2018 Lab1
date:   2020-02-10
author: hding
catalog: true
tags:
   - database
---
# [Lab1](https://15445.courses.cs.cmu.edu/fall2018/project1/)

## Overview 
实现BufferPoolManager,它需要用到LRU算法，可以选择性使用Extendible Hash Table。

## Task1 - Extendible Hash Table
### Specification 
使用无序的bucket和唯一的KV来实现Extendible Hash Table,这张表需要实现inset、delete和find操作，同时不需要指定这张表的maxSize,这张表的size随着需要(insert)而扩容,但是不需要缩小。
![Extendible Hashing](/img/DataBase/ExtendibleHashing.jpeg)
Figure 1 : 扩容之前

![Extendible Hashing2](/img/DataBase/ExtendibleHashing2.jpeg)
Figure 2 : 扩容之后

### Solution 

#### KV存放位置
我们将每个KV存于相对应的bucket中,首先定义bucket:
```c++
struct Bucket {
    Bucket() = default;
    explicit Bucket(size_t i, int d) : id(i), depth(d) {}
    std::map<K, V> items;          // key-value pairs
    size_t id = 0;                 // id of Bucket
    int depth = 0;                 // local depth counter
  };
```
因此KV存在于每个bucket中的map中,而我们的table会有一个bucket数组:
```c++
std::vector<std::shared_ptr<Bucket>> bucket_;    // 桶数组
```
假设我们有了hash，我们可以find对应的bucket,再到该bucket中找到对应的KV。



#### 如何找到某个key对应的bucket
首先假设我们有一个hash function,得到某一hash值,然后我们根据这个hash值与globalDepth，可以得到对应的bucket
```c++
size_t bucket_id = HashKey(key) & ((1 << globalDepth) - 1);
```
在这里我们取hash值的末{globalDepth}**bit**位(与figure展示正好相反)。



#### 当需要扩容时如何split某个bucket
我们将在构造table的时候，指定所有bucket的每个的maxKVSize(所能容纳的KV的上限),当我们不断insert KV至同一个bucket而大于其maxKVSize的时候,我们就需要split该bucket:
```c++
// 分裂新桶
template <typename K, typename V>
std::shared_ptr<typename ExtendibleHash<K, V>::Bucket>
ExtendibleHash<K, V>::split(std::shared_ptr<Bucket> &old_bucket) {
    // 先创建一个新桶
    auto new_bucket = std::make_shared<Bucket>(0, old_bucket->depth);
    // 注意：这里是while循环
    while(new_bucket->items.empty()) {
        // 先将旧桶与新桶的深度加一
        old_bucket->depth++;
        new_bucket->depth++;
        // 下面的for循环实现两个桶的分配
        for(auto it = old_bucket->items.begin(); it != old_bucket->items.end();) {
            // 注意下面两个HashKey与后面的式子是不一样的
            if (HashKey(it->first) & (1 << (old_bucket->depth - 1))) { // 当再进一位时对应的是1，将该KV放入new_bucket
                new_bucket->items.insert(*it);
                new_bucket->id = HashKey(it->first) & ((1 << old_bucket->depth) - 1);
                it = old_bucket->items.erase(it);
            } else { // 为0则不动
                ++it;
            }
        }

        // 如果old_bucket桶的map为空，说明旧桶里的KV全都跑到新桶里了,深度不够，还要进行循环
        if(old_bucket->items.empty()) {
            old_bucket->items.swap(new_bucket->items);
            old_bucket->id = new_bucket->id;
        }
    }

    ++bucket_count_;
    return new_bucket;
}
```


#### split之后扩容bucket数组并重新分配所有的bucket
在split之后，需要比较split之后的new_bucket的localDepth与table的globalDepth来决定是否需要增加globalDepth,毕竟从原理上讲,table应当满足 globalDepth >= localDepth:
```c++
// 先记录旧的下标和全局深度，因为split函数会更改old_bucket的状态
auto old_index = old_bucket->id;
auto old_depth = old_bucket->depth;

std::shared_ptr<Bucket> new_bucket = split(old_bucket);
// 若插入的桶的局部深度大于全局深度，则要扩展桶数组
if(old_bucket->depth > globalDepth) {
	auto size = bucket_.size(); // bucket_位bucket数组
    auto factor = (1 << (old_bucket->depth - globalDepth)); // 计算bucket数组需要扩大的倍数

    globalDepth = old_bucket->depth;
    bucket_.resize(bucket_.size()*factor);

    // 修改和添加要插入的桶和新建的桶
    bucket_[old_bucket->id] = old_bucket;
    bucket_[new_bucket->id] = new_bucket;

    // 遍历桶数组
    for(size_t i = 0; i < size; ++i) {
        if(bucket_[i]) { // 如果该数组的位置上之前有指向某个bucket
            if(i < bucket_[i]->id){
                 bucket_[i].reset();
            } else {
              // 指向相同bucket的数组index之间的间隔
              auto step = 1 << bucket_[i]->depth; 
              for(size_t j = i + step; j < bucket_.size(); j += step) {
                   bucket_[j] = bucket_[i];
                  }
               }
            }
        }
} else { // 若插入的桶的局部深度小于等于全局深度
    for (size_t i = old_index; i < bucket_.size(); i += (1 << old_depth)) {
         bucket_[i].reset();
    }

    bucket_[old_bucket->id] = old_bucket;
    bucket_[new_bucket->id] = new_bucket;

    auto step = 1 << old_bucket->depth;
    for (size_t i = old_bucket->id + step; i < bucket_.size(); i += step) {
         bucket_[i] = old_bucket;
    }
    for (size_t i = new_bucket->id + step; i < bucket_.size(); i += step) {
         bucket_[i] = new_bucket;
    }
}
```



#### insert的实现
当找到对应的bucket后,insert时需要考虑下列几种case:
1. 无bucket
2. 有bucket但是bucket中已经有该key
3. 有bucket且该bucket中无该key，同时有位置
4. 有bucket且该bucket中无该key，但是无位置

```c++
template <typename K, typename V>
void ExtendibleHash<K, V>::Insert(const K &key, const V &value) {
    size_t bucket_id = HashKey(key) & ((1 << depth) - 1);

    // 找到插入的位置，如果为空则新建一个桶
    if(bucket_[bucket_id] == nullptr) {
        bucket_[bucket_id] = std::make_shared<Bucket>(bucket_id, depth);
    }
    auto old_bucket = bucket_[bucket_id];

    // 如果该位置有值，则覆盖
    if(old_bucket->items.find(key) != old_bucket->items.end()) {
        old_bucket->items[key] = value;
        return;
    }

    // 插入键值对
    old_bucket->items.insert({key, value});

    // 需要分裂桶以及重新分配
    if(old_bucket->items.size() > bucket_max_KV_size_) {
        // 先记录旧的下标和全局深度
        auto old_index = old_bucket->id;
        auto old_depth = old_bucket->depth;

        std::shared_ptr<Bucket> new_bucket = split(old_bucket);

        // 溢出了就改回原来的深度
        if(new_bucket == nullptr) {
            bucket->depth = old_depth;
            return;
        }

        // 若插入的桶的局部深度大于全局深度，则要扩展桶数组
        // 见之前的代码“在扩容之后重新分配所有的bucket”
    }
}
```




## Task2
### Specification

### Solution



























